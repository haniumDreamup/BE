# 실제 Vision AI 앱 구현 방식 조사

## 조사 대상 앱
1. **Be My AI** (Be My Eyes) - GPT-4 기반
2. **Google Lookout** - Gemini/Flamingo 기반
3. **Envision Glasses** - GPT 기반
4. **Microsoft Seeing AI** - Azure Cognitive Services

---

## 1. Be My AI (Be My Eyes)

### 핵심 특징
- **자연스러운 대화체** 설명
- **극도로 상세한** 묘사
- **대화형 후속 질문** 지원

### 실제 출력 예시

**고양이 사진:**
```
이 사진에는 고양이가 있습니다.
고양이는 주황색과 흰색 털을 가지고 있으며,
부드러워 보이는 파란색 쿠션 위에 누워 있습니다.
고양이의 눈은 초록색이고, 편안하게 쉬고 있는 것처럼 보입니다.
```

**Apple 이벤트 초대장:**
```
이 이미지는 소셜 미디어에 게시된 Apple 이벤트 초대장입니다.
상단에는 Apple 로고가 있고,
중앙에는 "Wonderlust" 텍스트가 크게 표시되어 있으며,
하단에는 날짜와 시간 정보가 있습니다.
배경은 청록색 그라데이션으로 구성되어 있습니다.
```

**컵 사진:**
```
테이블 위에 파란색 컵이 있습니다.
컵은 광택이 있는 표면에 놓여있어
테이블에 컵의 반사가 보입니다.
```

### 응답 형식 특징
1. **자연스러운 문단 형식** (마크다운 구조 없음)
2. **색상, 위치, 상태 모두 포함**
3. **시각적 세부사항 강조** (반사, 질감, 배치)
4. **컨텍스트 제공** (무엇을 위한 것인지)

### 대화형 기능
- 초기 설명 후 후속 질문 가능
- "무슨 색이야?", "읽을 수 있는 글자가 있어?" 등
- ChatGPT처럼 자연스러운 대화

---

## 2. Google Lookout

### 핵심 특징
- **구조화된 문장** ("In this image, I can see...")
- **공간 정보** 강조 (foreground, background)
- **계층적 정보 구조**

### 실제 출력 예시

**해변의 개:**
```
In this image, I can see a dog is running on the sand.
I can also see a ball in its mouth.
In the background, I can see the water, mountains, and the sky.
```
(한국어 번역)
```
이 사진에서 개가 모래 위를 달리고 있는 것을 볼 수 있습니다.
개의 입에 공이 있는 것도 보입니다.
배경에는 물, 산, 하늘이 보입니다.
```

**Tea Shack:**
```
In this picture we can see there is a person standing,
and to the side there is a wooden object,
behind it there is a machine and a few other things,
and there is the writing tea shack.
```

### 응답 형식 특징
1. **"In this image/picture"로 시작**
2. **공간 레이어 구분** (foreground → middle → background)
3. **"I can see" 반복 사용** (명확성)
4. **객체 → 위치 → 텍스트 순서**

### 7가지 모드
1. **Text mode** - 텍스트 스캔 및 읽기
2. **Documents mode** - 전체 페이지 캡처
3. **Explore mode** - 주변 환경 탐색
4. **Images mode** - 상세 이미지 설명 + Q&A
5. **Food labels mode** - 식품 라벨 인식
6. **Currency mode** - 지폐 인식
7. **Find mode** - 특정 물체 찾기 (거리/방향 안내)

---

## 3. Envision Glasses 2.5

### 핵심 특징
- **즉각적인 Alt-text 스타일** 간략 설명
- **Story-like 상세 설명** (2024 업데이트)
- **환각 현상 최소화** (정확도 개선)
- **Ask Envision** 대화형 기능

### 응답 형식
**Phase 1: 간략 설명 (Alt-text)**
```
A person standing in a kitchen with utensils on the counter.
```

**Phase 2: 상세 설명 (Story-like)**
```
주방에 사람이 서 있습니다.
왼쪽 카운터 위에는 칼, 도마, 주걱이 놓여있고,
오른쪽에는 냄비 2개와 프라이팬 1개가 보입니다.
뒤쪽 벽에는 시계가 걸려있고 오전 10시 30분을 가리키고 있습니다.
창문으로 햇빛이 들어와 밝은 분위기입니다.
```

**Phase 3: Ask Envision (후속 질문)**
- "테이블 위에 뭐가 있어?"
- "저 식물은 무슨 종류야?"
- "자동차 색은 뭐야?"

### 2024 주요 개선사항
1. **Instant Results** - 빠른 응답 속도
2. **환각 현상 대폭 감소** - 더 정확한 설명
3. **풍부한 디테일** - 이전보다 2-3배 자세함

---

## 4. Microsoft Seeing AI

### 7가지 채널 (모드)
1. Short Text - 짧은 텍스트 즉시 읽기
2. Documents - 문서 전체 읽기
3. Products - 바코드 스캔
4. People - 사람 인식 + 표정
5. **Scenes** - 장면 설명
6. Colors - 색상 인식
7. Handwriting - 손글씨 인식

### Scene 모드 특징
- **간결하고 명확한** 한 문장 설명
- **주요 객체 3-5개** 나열
- **사람 수와 행동** 포함
- **즉시 오디오 출력**

---

## 비교 분석

| 앱 | 설명 길이 | 구조 | 후속 질문 | 특징 |
|---|---|---|---|---|
| **Be My AI** | 매우 상세 | 자연스러운 문단 | ✅ | 대화형, 스토리텔링 |
| **Lookout** | 상세 | 구조화 ("I can see") | ✅ | 공간 계층, 7가지 모드 |
| **Envision** | 2단계 (간략→상세) | Alt-text → Story | ✅ | 빠른 응답, 정확도 |
| **Seeing AI** | 간결 | 한 문장 요약 | ❌ | 즉시성, 7채널 |

---

## BIF-AI 적용 전략

### 현재 문제점
1. ❌ **정보 부족** - "사람 없음" 같은 간단한 정보만
2. ❌ **맥락 부족** - 전체 상황 파악 어려움
3. ❌ **행동 가이드 부족** - "다음에 뭘 해야 하지?"
4. ❌ **후속 질문 불가** - 추가 정보 얻을 방법 없음

### 개선 방향

#### 1. **3단계 응답 구조** (Envision 방식)

**Phase 1: 빠른 요약 (2-3초)**
```
실내 주방. 음식 준비 중.
```

**Phase 2: 상세 설명 (자동 전달)**
```
🍽️ 주방입니다

**있는 것:**
- 가스레인지 1개 (불 켜져 있음)
- 냄비 1개 (김이 나요)
- 도마 1개
- 칼 2개
- 당근 3개, 감자 2개

**사람:**
- 사람 1명
- 앞치마 입고 있어요
- 요리 중

⚠️ 가스불이 켜져있어요. 조리 중입니다.

💡 음식이 익을 때까지 기다려야 해요.
   타이머를 맞추면 좋아요.
```

#### 2. **공간 정보 추가** (Lookout 방식)

```
**앞쪽:**
- 횡단보도 (바로 앞 2m)
- 신호등 (빨간불)

**왼쪽:**
- 차 1대 (정지 중)

**오른쪽:**
- 사람 2명 (서 있음)

**뒤쪽:**
- 건물 1개 (편의점)
```

#### 3. **자연스러운 스토리텔링** (Be My AI 방식)

```
지금 횡단보도 앞에 있습니다.
신호등은 빨간불이에요.
왼쪽에 차 1대가 멈춰있고,
오른쪽에는 사람 2명이 신호를 기다리고 있어요.

초록불이 켜지면 건너도 안전합니다.
초록불이 켜지기를 기다리세요.
```

#### 4. **시각적 디테일 강화**

**색상:**
- "빨간불", "파란색 컵", "흰색 벽"

**상태:**
- "김이 나는 국", "녹슨 철봉", "깨끗한 바닥"

**질감:**
- "부드러운 쿠션", "딱딱한 의자", "미끄러운 바닥"

**위치:**
- "테이블 위에", "왼쪽 구석에", "천장에 매달려"

---

## 최종 권장 프롬프트 구조

```
당신은 경계선 지능 사용자(IQ 70-85)의 눈입니다.

응답 형식:

1. **한 줄 요약** (장소 + 주요 활동)
   예: "실내 주방. 요리 중"

2. **⚠️ 위험** (있으면)
   - [위험물] + [즉시 행동]
   - 예: "⚠️ 가스불 켜짐. 조리 중이니 가까이 가지 마세요"

3. **📍 있는 것** (공간별 정리)
   앞쪽:
   - [객체 + 개수 + 상태]

   왼쪽/오른쪽:
   - [객체 + 개수 + 상태]

   뒤쪽:
   - [객체 + 개수 + 상태]

4. **👤 사람** (있으면)
   - 몇 명
   - 무엇을 하는지
   - 표정/감정 (😊😢😠😮)

5. **📝 글자** (읽을 수 있는 텍스트 그대로)
   - 요약 금지, 있는 그대로

6. **💡 지금 상황 설명** (Be My AI 스타일)
   - 2-3문장으로 전체 맥락 설명
   - 자연스러운 스토리텔링

7. **🎯 다음 행동** (구체적 가이드)
   - 지금 무엇을 해야 하는지
   - 몇 분 기다려야 하는지
   - 어디로 가야 하는지

작성 원칙:
- 85% 이상 확신만 전달
- 추측 금지 ("아마도" ❌)
- 구체적 수치 ("3개", "2명")
- 색상, 위치, 상태 모두 포함
- 짧은 문장 (10단어 이하)
- 이모지 활용
```

---

## 참고 자료

1. Be My Eyes - GPT-4 Integration (2024)
2. Google Lookout - Gemini Update (2024)
3. Envision Glasses 2.5 - Scene Description Evolution (2024)
4. Microsoft Seeing AI - Cognitive Services Documentation
5. W3C WAI - Visual Description Guidelines
6. WCAG 2.2 - Cognitive Accessibility
