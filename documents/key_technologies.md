# BIF-AI 시스템: 주요 적용 기술 명세서

## 1. S/W (소프트웨어) 기술

### 1.1. 실시간 인지 보조 기능

#### 가. 시나리오: 요리 중 다음 단계 인지 지원
사용자가 레시피를 따라 요리하던 중, 현재 진행 상황과 다음 단계를 잊어버린 상황.
- **사용자 질문 (음성):** "다음에 뭐 해야 하지?"
- **시스템 응답 (음성):** "지금 냄비에 양파와 다진 고기가 있네요. 레시피에 따라 소스를 넣고 5분간 볶을 차례입니다."

#### 나. 적용 알고리즘 및 기술

1.  **실시간 컨텍스트 분석기 (Real-time Context Analyzer)**
    -   **알고리즘:**
        -   **객체 탐지 (Object Detection):** `YOLOv8 (You Only Look Once v8)` 알고리즘을 활용하여 카메라 영상 프레임 내의 주요 객체(냄비, 프라이팬, 각종 재료, 조리 도구 등)를 실시간으로 탐지하고 분류합니다.
        -   **광학 문자 인식 (OCR):** `Tesseract` 또는 `EasyOCR` 라이브러리를 통해 레시피 책이나 조미료 통에 적힌 텍스트를 추출하여 데이터화합니다.
    -   **이론적 배경 (YOLO):** YOLO는 이미지를 그리드로 나눈 뒤, 각 그리드 셀에서 직접 바운딩 박스(Bounding Box)와 클래스 확률(Class Probability)을 예측하는 1단계 탐지기(One-stage detector)입니다. 이 방식은 R-CNN 계열의 2단계 탐지기보다 속도가 매우 빨라 실시간 처리에 적합합니다.

2.  **LLM 기반 상황 추론 및 가이드 생성기 (LLM-based Context Interpreter)**
    -   **알고리즘:**
        -   탐지된 객체, 텍스트, 사용자 음성(STT 변환 후) 데이터를 구조화된 프롬프트(예: `{"objects": ["pot", "onion"], "user_query": "what_next"}`)로 구성합니다.
        -   이 프롬프트를 `GPT-4`와 같은 거대 언어 모델(LLM)에 입력하여 현재 상황('양파를 볶는 중')을 추론하고, 일반적인 요리 지식과 OCR로 인식된 레시피를 바탕으로 가장 적절한 다음 행동 가이드를 생성합니다.
    -   **이론적 배경 (Transformer & LLM):** LLM의 기반이 되는 트랜스포머 아키텍처는 '어텐션 메커니즘(Attention Mechanism)'을 사용하여 입력된 데이터(단어, 객체 태그 등) 간의 관계 중요도를 계산합니다. 이를 통해 모델은 어떤 정보에 집중해야 할지 학습하고, 문맥에 맞는 자연스럽고 논리적인 문장을 생성할 수 있습니다.

3.  **음성 입출력 인터페이스 (Voice Interface)**
    -   **기술:** Google의 `Speech-to-Text (STT)` API로 사용자 음성을 텍스트로 변환하고, 생성된 가이드 텍스트를 `Text-to-Speech (TTS)` API를 통해 자연스러운 음성으로 변환하여 사용자에게 전달합니다.

### 1.2. 사용자 맞춤형 네비게이션 기능

#### 가. 시나리오: 인지 부하가 적은 경로로 병원 길안내
사용자가 현재 위치에서 근처 병원까지 길안내를 요청하는 상황. 시스템은 가장 짧은 길이 아닌, 가장 이해하기 쉬운 길을 안내해야 함.

#### 나. 적용 알고리즘 및 기술

1.  **BIF 특화 경로 탐색 알고리즘**
    -   **알고리즘:** `A* (A-Star) 탐색 알고리즘`을 기반으로 하되, 비용 함수(Cost Function)를 독자적으로 설계합니다.
        -   `Total Cost = g(n) + h(n) + w * c(n)`
        -   `g(n)`: 시작점에서 현재 노드까지의 실제 거리
        -   `h(n)`: 현재 노드에서 목적지까지의 추정 거리 (Heuristic)
        -   `c(n)`: 경로의 '인지 복잡도' 점수 (예: 회전 횟수, 횡단보도 수, 지하도/육교 유무)
        -   `w`: 복잡도에 대한 가중치 (사용자 설정에 따라 조절 가능)
    -   **이론적 배경 (A* Algorithm):** A* 알고리즘은 다익스트라(Dijkstra) 알고리즘에 휴리스틱(목적지까지의 추정 값)을 추가하여, 불필요한 노드의 탐색을 줄이는 효율적인 최단 경로 탐색 알고리즘입니다. 본 시스템에서는 여기에 '인지 복잡도'라는 차원을 추가하여 다목적 최적화(Multi-objective optimization)를 수행합니다.

2.  **센서 퓨전 기반 위치 보정**
    -   **기술:** GPS 신호가 약한 도심이나 실내에서 `IMU (관성 측정 장치)`의 가속도계, 자이로스코프 데이터를 `보행자 추측 항법 (PDR, Pedestrian Dead Reckoning)` 알고리즘에 적용합니다. 이를 통해 마지막 GPS 신호 위치로부터의 이동 거리와 방향을 추정하여 현재 위치를 보정하고, 끊김 없는 안내를 제공합니다.

---

## 2. H/W (하드웨어) 기술

### 2.1. 생활 안전망 (낙상 감지)

#### 가. 시나리오: 자택 내 낙상 감지 및 긴급 알림
사용자가 집 안에서 발을 헛디뎌 넘어진 후 움직이지 못하는 상황.

#### 나. 적용 알고리즘 및 기술

1.  **다중 센서 퓨전 기반 낙상 감지 모델**
    -   **알고리즘:**
        -   **(영상 분석)** `MediaPipe Pose`와 같은 실시간 자세 추정 기술을 사용하여 영상 속 사용자의 주요 관절(Keypoints) 위치를 추적합니다. '낙상'은 '수직 방향으로의 급격한 위치 변화'와 '바닥에 머무르는 상태 지속'의 조합으로 정의됩니다.
        -   **(IMU 분석)** 목걸이형 기기 내 IMU 센서가 측정한 가속도 값의 크기(Vector Magnitude)가 특정 임계치를 초과하는 '자유낙하 및 충격' 패턴을 감지합니다.
        -   **(결정 모델)** 위 두 알고리즘의 결과를 입력으로 받는 간단한 `결정 트리(Decision Tree)` 또는 `로지스틱 회귀(Logistic Regression)` 모델을 통해, 두 조건이 모두 충족될 때 최종적으로 '낙상'으로 판단하여 오탐을 최소화합니다.
    -   **이론적 배경 (Pose Estimation):** 딥러닝 기반의 자세 추정 모델은 대규모 이미지 데이터셋을 통해 신체 부위의 일반적인 형태와 위치를 학습합니다. 이를 통해 별도의 마커 없이 영상만으로 각 관절의 2D 또는 3D 좌표를 높은 정확도로 추정할 수 있습니다. 