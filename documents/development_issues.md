# 프로젝트 개발: 기술적 문제점 및 해결 경험

본격적인 기능 구현에 앞서, 안정적이고 확장 가능한 백엔드 시스템을 구축하는 과정에서 다음과 같은 핵심적인 기술적 과제에 직면했습니다.

## 1. 문제점 1: 이종(異種) 플랫폼(모바일 앱 ↔ 스프링 백엔드) 간의 효율적인 데이터 교환 프로토콜 설계

-   **문제 상황:** BIF-AI 시스템은 사용자의 스마트폰(엣지)에서 수집된 다양한 센서 정보와 AI 분석 결과를 스프링 백엔드로 전송해야 합니다. 이 데이터는 단순 텍스트부터 이미지 분석 결과, 위치 정보, 자세 추정 데이터까지 종류가 매우 다양합니다. 초기에는 범용적인 JSON 기반의 REST API를 구상했지만, 다음과 같은 문제에 부딪혔습니다.
    1.  **데이터 구조의 복잡성:** 모든 종류의 데이터를 하나의 DTO(Data Transfer Object)로 처리하려니, 특정 상황에서는 불필요한 필드가 너무 많아져 데이터가 비대해지고 파싱이 복잡해졌습니다.
    2.  **실시간성 한계:** 낙상이나 긴급 상황과 같이 즉각적인 처리가 필요한 이벤트를 일반적인 HTTP 요청-응답 모델로 처리하는 것이 과연 최선인지에 대한 기술적 고민이 필요했습니다.

-   **해결 과정:**
    1.  **상황별 DTO 분리 및 API 엔드포인트 세분화:** 모든 것을 하나의 API로 처리하려는 방식을 버리고, **상황에 따라 API 엔드포인트와 DTO를 명확하게 분리**했습니다. 예를 들어, '일상 약 복용 알림'을 위한 정보 전송 API와 '긴급 낙상 감지' API는 서로 다른 DTO와 처리 로직을 갖도록 설계했습니다. 이는 각 API의 역할을 명확히 하고 데이터의 정합성을 높이는 효과를 가져왔습니다.
    2.  **Pragmatic Protocol 선택 (REST + α):** 실시간 통신을 위해 gRPC나 WebSocket 도입을 검토했으나, 프로젝트 초기 단계의 개발 복잡성과 프론트엔드(모바일)와의 연동 용이성을 고려하여 **REST API를 주력 통신 방식으로 채택**했습니다. 대신, 긴급 이벤트는 별도의 경량화된 엔드포인트로 분리하고, 향후 고도화 시점에 해당 기능만 WebSocket으로 전환할 수 있도록 확장성을 열어두는 실용적인 접근 방식을 선택했습니다.

## 2. 문제점 2: 외부 LLM 서비스에 대한 의존성 관리 및 유연한 전환 구조 설계

-   **문제 상황:** 저희 백엔드는 OpenAI, Google Gemini 등 외부 LLM 서비스와 연동하여 사용자의 상황을 최종 판단해야 합니다. 특정 업체의 LLM 서비스에 코드가 종속(Vendor Lock-in)될 경우, 향후 더 좋은 성능이나 합리적인 비용의 서비스가 등장했을 때 유연하게 대처하기 어렵다는 문제가 있었습니다. 각 서비스는 고유의 SDK와 API 명세를 가지고 있어, 서비스 변경 시마다 상당한 코드 수정이 예상되었습니다.

-   **해결 과정:**
    1.  **추상화 계층(Abstraction Layer) 도입:** 이 문제를 해결하기 위해, 객체 지향의 **어댑터(Adapter) 패턴**과 스프링의 **의존성 주입(DI)** 원리를 활용했습니다.
    2.  **공통 인터페이스 정의:** 먼저, LLM의 핵심 기능을 정의하는 우리만의 공통 인터페이스(`LlmService.java`)를 만들었습니다. 여기에는 `assessSituation(context)`와 같은 추상 메소드가 포함됩니다.
    3.  **구현체(Adapter) 작성:** 그 후, 각 LLM 서비스별로 이 인터페이스를 구현하는 클래스(`OpenAiLlmServiceImpl.java`, `GeminiLlmServiceImpl.java` 등)를 작성했습니다. 이 클래스들은 각자의 SDK를 사용하여 외부 API와 통신하는 구체적인 로직을 담당합니다.
    4.  **유연한 서비스 전환:** 실제 비즈니스 로직에서는 특정 구현체가 아닌 `LlmService` 인터페이스에만 의존합니다. 스프링의 `@Service`, `@Qualifier` 또는 `@Profile` 같은 어노테이션을 활용하여, 설정 파일 변경만으로 사용하고 싶은 LLM 서비스를 손쉽게 교체할 수 있는 구조를 완성했습니다. 이는 코드의 재사용성을 높이고, 향후 새로운 LLM이 등장하더라도 신속하게 시스템에 통합할 수 있는 강력한 유연성을 제공합니다. 