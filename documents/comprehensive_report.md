# BIF-AI 인지 보조 시스템 개발 보고서

## 1. 개요

### 1.1. 개발 배경 및 필요성

경계선 지능(BIF, Borderline Intellectual Functioning) 인구는 지적장애 범주에 속하지 않으나, 평균 범위(IQ 70-85) 하단에 속하는 인지 능력으로 인해 일상생활 과업 수행, 복합적 상황 판단, 사회적 상호작용 등에서 다양한 어려움을 겪고 있습니다. 이들은 적절한 지원 없이는 잠재력을 완전히 발휘하기 어렵고, 사회적으로 고립될 위험이 있습니다. 따라서 이들의 독립적인 삶을 지원하고 사회 참여를 촉진할 수 있는 실질적인 인지 보조 도구의 개발이 시급합니다.

### 1.2. 프로젝트 목표

본 프로젝트의 최종 목표는 **웨어러블 카메라와 인공지능(AI) 기술을 결합한 실시간 상황 인식 기반의 인지 보조 시스템을 개발**하는 것입니다. 이를 통해 사용자의 인지적 부담을 경감시키고, 일상 과업 수행 능력을 향상시키며, 위급 상황에 대한 안전망을 제공함으로써 궁극적으로 경계선 지능 사용자의 자립과 삶의 질 향상에 기여하고자 합니다.

---

## 2. 개발 내용

### 2.1. 시스템 정의

본 시스템은 목걸이형 웨어러블 카메라로 사용자의 주변 환경 데이터를 실시간으로 수집하고, 이를 AI 서버로 전송하여 거대 언어 모델(LLM)이 상황을 분석 및 판단한 후, 사용자에게 필요한 음성/텍스트 가이드를 스마트 기기로 제공하는 지능형 보조 시스템입니다.

### 2.2. 주요 기능 및 개발 범위

1.  **실시간 인지 보조 기능**
    -   **내용:** 카메라 영상 및 음성 인식을 통해 요리, 쇼핑, 대중교통 이용, 대화 등 복합적인 일상 활동의 맥락을 분석하고, 단계별 수행 가이드 또는 사회적 상호작용 팁을 제공합니다.
    -   **범위:** 객체/텍스트/음성 인식 모듈, 상황 판단 LLM 모델, 가이드 생성 및 제공 인터페이스 개발.

2.  **사용자 맞춤형 네비게이션 기능**
    -   **내용:** 인지적 부하가 적은 경로(예: 단순 경로, 시각적 표지 중심)를 우선적으로 탐색하고, 실내외 및 대중교통 환경에서 단계별 길안내를 제공합니다.
    -   **범위:** BIF 맞춤형 경로 탐색 알고리즘, GPS 기반 위치 추적, 단계별 안내 UI/UX 개발.

3.  **생활 안전망 기능**
    -   **내용:** GPS를 이용한 실시간 위치 공유 및 안심 구역 설정, 가속도 센서 및 영상 분석을 통한 낙상 등 위급 상황 자동 감지 및 긴급 연락처 알림 기능을 제공합니다.
    -   **범위:** 위치 정보 관리 모듈, 낙상 감지 알고리즘, 긴급 알림(SMS/Push) 시스템 개발.

4.  **자동화된 일정 관리 기능**
    -   **내용:** 사용자의 반복적인 생활 패턴을 시스템이 자동 분석하여, 병원 방문, 약 복용 시간 등 주요 일정을 예측하고 리마인더를 제공합니다.
    -   **범위:** 사용자 활동 데이터 로깅 및 패턴 분석, 개인화된 알림 생성 시스템 개발.

---

## 3. 시스템 아키텍처

### 3.1. 구성도

```mermaid
graph TD
    subgraph "사용자 환경 (Client-side)"
        A[목걸이형 카메라<br/>- 영상/음성 스트리밍]
        B[스마트 기기<br/>- 음성/텍스트 가이드 출력<br/>- GPS/센서 데이터]
    end

    subgraph "서버 환경 (Server-side)"
        C[API Gateway]
        D[실시간 데이터 처리<br/>(영상/음성 분석)]
        E[AI 판단 엔진 (LLM)<br/>- 상황 분석<br/>- 가이드 생성]
        F[기능별 로직<br/>- 네비게이션<br/>- 안전<br/>- 일정]
        G[데이터베이스<br/>- 사용자 정보<br/>- 활동 로그]
    end

    A --> |HTTPS/WSS| C
    B -- |HTTPS| C
    C --> D
    D <--> E
    E --> F
    F <--> G
    C --> B
```

### 3.2. 데이터 흐름

1.  **(데이터 수집)** 사용자의 웨어러블 카메라와 스마트 기기가 실시간 영상, 음성, 센서(GPS 등) 데이터를 서버로 전송합니다.
2.  **(데이터 처리 및 분석)** 서버는 수신된 데이터를 분석 모듈로 전달하여 상황 인식을 위한 기초 정보(객체, 텍스트 등)를 추출합니다.
3.  **(AI 판단)** AI 판단 엔진(LLM)이 분석된 정보를 바탕으로 사용자의 현재 상황과 의도를 추론하고, 필요한 지원의 종류와 내용을 결정하여 맞춤형 가이드를 생성합니다.
4.  **(기능 수행 및 응답)** 생성된 가이드는 기능별 로직을 거쳐 최종 가공된 후, API를 통해 사용자의 스마트 기기로 전송되어 음성 또는 텍스트 형태로 출력됩니다. 모든 데이터는 암호화되어 안전하게 처리됩니다.

---

## 4. 주요 적용 기술

### 4.1. S/W (소프트웨어) 기술

#### 4.1.1. 실시간 인지 보조 기능
- **시나리오: 요리 중 다음 단계 인지 지원**
    - 사용자가 레시피를 따라 요리하던 중, 현재 진행 상황과 다음 단계를 잊어버린 상황.
    - **사용자 질문 (음성):** "다음에 뭐 해야 하지?"
    - **시스템 응답 (음성):** "지금 냄비에 양파와 다진 고기가 있네요. 레시피에 따라 소스를 넣고 5분간 볶을 차례입니다."
- **적용 알고리즘 및 기술**
    1.  **실시간 컨텍스트 분석기 (Real-time Context Analyzer)**
        -   **알고리즘:**
            -   **객체 탐지 (Object Detection):** `YOLOv8 (You Only Look Once v8)` 알고리즘을 활용하여 카메라 영상 프레임 내의 주요 객체(냄비, 프라이팬, 각종 재료, 조리 도구 등)를 실시간으로 탐지하고 분류합니다.
            -   **광학 문자 인식 (OCR):** `Tesseract` 또는 `EasyOCR` 라이브러리를 통해 레시피 책이나 조미료 통에 적힌 텍스트를 추출하여 데이터화합니다.
        -   **이론적 배경 (YOLO):** YOLO는 이미지를 그리드로 나눈 뒤, 각 그리드 셀에서 직접 바운딩 박스(Bounding Box)와 클래스 확률(Class Probability)을 예측하는 1단계 탐지기(One-stage detector)입니다. 이 방식은 R-CNN 계열의 2단계 탐지기보다 속도가 매우 빨라 실시간 처리에 적합합니다.
    2.  **LLM 기반 상황 추론 및 가이드 생성기 (LLM-based Context Interpreter)**
        -   **알고리즘:**
            -   탐지된 객체, 텍스트, 사용자 음성(STT 변환 후) 데이터를 구조화된 프롬프트(예: `{"objects": ["pot", "onion"], "user_query": "what_next"}`)로 구성합니다.
            -   이 프롬프트를 `GPT-4`와 같은 거대 언어 모델(LLM)에 입력하여 현재 상황('양파를 볶는 중')을 추론하고, 일반적인 요리 지식과 OCR로 인식된 레시피를 바탕으로 가장 적절한 다음 행동 가이드를 생성합니다.
        -   **이론적 배경 (Transformer & LLM):** LLM의 기반이 되는 트랜스포머 아키텍처는 '어텐션 메커니즘(Attention Mechanism)'을 사용하여 입력된 데이터(단어, 객체 태그 등) 간의 관계 중요도를 계산합니다. 이를 통해 모델은 어떤 정보에 집중해야 할지 학습하고, 문맥에 맞는 자연스럽고 논리적인 문장을 생성할 수 있습니다.
    3.  **음성 입출력 인터페이스 (Voice Interface)**
        -   **기술:** Google의 `Speech-to-Text (STT)` API로 사용자 음성을 텍스트로 변환하고, 생성된 가이드 텍스트를 `Text-to-Speech (TTS)` API를 통해 자연스러운 음성으로 변환하여 사용자에게 전달합니다.

#### 4.1.2. 사용자 맞춤형 네비게이션 기능
- **시나리오: 인지 부하가 적은 경로로 병원 길안내**
    - 사용자가 현재 위치에서 근처 병원까지 길안내를 요청하는 상황. 시스템은 가장 짧은 길이 아닌, 가장 이해하기 쉬운 길을 안내해야 함.
- **적용 알고리즘 및 기술**
    1.  **BIF 특화 경로 탐색 알고리즘**
        -   **알고리즘:** `A* (A-Star) 탐색 알고리즘`을 기반으로 하되, 비용 함수(Cost Function)를 독자적으로 설계합니다.
            -   `Total Cost = g(n) + h(n) + w * c(n)`
            -   `g(n)`: 시작점에서 현재 노드까지의 실제 거리
            -   `h(n)`: 현재 노드에서 목적지까지의 추정 거리 (Heuristic)
            -   `c(n)`: 경로의 '인지 복잡도' 점수 (예: 회전 횟수, 횡단보도 수, 지하도/육교 유무)
            -   `w`: 복잡도에 대한 가중치 (사용자 설정에 따라 조절 가능)
        -   **이론적 배경 (A* Algorithm):** A* 알고리즘은 다익스트라(Dijkstra) 알고리즘에 휴리스틱(목적지까지의 추정 값)을 추가하여, 불필요한 노드의 탐색을 줄이는 효율적인 최단 경로 탐색 알고리즘입니다. 본 시스템에서는 여기에 '인지 복잡도'라는 차원을 추가하여 다목적 최적화(Multi-objective optimization)를 수행합니다.
    2.  **센서 퓨전 기반 위치 보정**
        -   **기술:** GPS 신호가 약한 도심이나 실내에서 `IMU (관성 측정 장치)`의 가속도계, 자이로스코프 데이터를 `보행자 추측 항법 (PDR, Pedestrian Dead Reckoning)` 알고리즘에 적용합니다. 이를 통해 마지막 GPS 신호 위치로부터의 이동 거리와 방향을 추정하여 현재 위치를 보정하고, 끊김 없는 안내를 제공합니다.

### 4.2. H/W (하드웨어) 기술

#### 4.2.1. 생활 안전망 (낙상 감지)
- **시나리오: 자택 내 낙상 감지 및 긴급 알림**
    - 사용자가 집 안에서 발을 헛디뎌 넘어진 후 움직이지 못하는 상황.
- **적용 알고리즘 및 기술**
    1.  **다중 센서 퓨전 기반 낙상 감지 모델**
        -   **알고리즘:**
            -   **(영상 분석)** `MediaPipe Pose`와 같은 실시간 자세 추정 기술을 사용하여 영상 속 사용자의 주요 관절(Keypoints) 위치를 추적합니다. '낙상'은 '수직 방향으로의 급격한 위치 변화'와 '바닥에 머무르는 상태 지속'의 조합으로 정의됩니다.
            -   **(IMU 분석)** 목걸이형 기기 내 IMU 센서가 측정한 가속도 값의 크기(Vector Magnitude)가 특정 임계치를 초과하는 '자유낙하 및 충격' 패턴을 감지합니다.
            -   **(결정 모델)** 위 두 알고리즘의 결과를 입력으로 받는 간단한 `결정 트리(Decision Tree)` 또는 `로지스틱 회귀(Logistic Regression)` 모델을 통해, 두 조건이 모두 충족될 때 최종적으로 '낙상'으로 판단하여 오탐을 최소화합니다.
        -   **이론적 배경 (Pose Estimation):** 딥러닝 기반의 자세 추정 모델은 대규모 이미지 데이터셋을 통해 신체 부위의 일반적인 형태와 위치를 학습합니다. 이를 통해 별도의 마커 없이 영상만으로 각 관절의 2D 또는 3D 좌표를 높은 정확도로 추정할 수 있습니다.

---

## 5. 개발 진척도

(신청일 기준)

| 구분 | 기능 | 설명 | 현재 진척도(%) |
| :--- | :--- | :--- | :--- |
| S/W | AI 백엔드 핵심 기능 개발 | 실시간 영상/음성 데이터 처리, LLM 연동을 통한 상황 분석 및 판단, 인지 보조 가이드 생성 API 구현 | 10 |
| | 네비게이션/안전/일정 기능 개발 | 사용자 맞춤형 길찾기, 낙상 감지 및 긴급 알림, 활동 패턴 기반의 일정 관리 서버 로직 구현 | 5 |
| | 스마트폰 클라이언트 앱 개발 | 서버로부터 가이드를 수신하여 출력하고, 센서 데이터를 서버로 전송하는 사용자 인터페이스(UI) 개발 | 5 |
| H/W | 목걸이형 카메라 제작 | 실시간 스트리밍이 가능한 저전력, 경량의 목걸이형 디바이스 프로토타입 설계 및 제작 | 0 |

### 5.1. 진척도 상세 설명

-   **S/W (소프트웨어):**
    -   **AI 백엔드 핵심 기능 (10%):** 시스템 아키텍처 설계 및 알고리즘 명세 작업이 완료되었습니다. 현재 Spring Boot 기반의 초기 프로젝트 구조가 설정된 상태입니다.
    -   **부가 기능 (5%):** 네비게이션, 안전망, 일정 관리에 대한 기능 정의 및 요구사항 명세가 완료되었습니다.
    -   **클라이언트 앱 (5%):** 주요 기능에 대한 화면 흐름 및 초기 UI 디자인이 완료된 상태입니다.
-   **H/W (하드웨어):**
    -   **카메라 제작 (0%):** 현재는 컨셉 구상 단계로, 실제 하드웨어 설계 및 프로토타입 제작은 착수되지 않았습니다.

---

## 6. 기대 효과

- **사용자 측면:** 일상 과업의 성공률을 높여 자신감을 증진시키고, 안전한 단독 외출을 가능하게 하여 독립적인 생활 반경을 확대합니다.
- **사회적 측면:** 경계선 지능 인구에 대한 사회적 지원 비용을 절감하고, 이들의 안정적인 사회 구성원으로서의 참여를 촉진하는 데 기여합니다.
- **기술적 측면:** 웨어러블 기술과 생성형 AI를 융합한 인지 보조 분야의 선도적 사례를 제시하고, 관련 기술 발전에 기여합니다.

---

## 7. 주요 용어 정의

- **경계선 지능 (BIF):** 지적장애와 평균 지능의 경계(IQ 70-85)에 위치하여, 추상적 사고, 계획, 문제 해결 등 복합적인 인지 처리 과정에서 어려움을 경험하는 상태.
- **상황 인식 AI (Context-Aware AI):** 센서 정보를 종합하여 사용자의 물리적, 사회적 환경과 맥락을 이해하고, 최적화된 정보를 제공하는 인공지능 기술.
- **인지 보조 시스템 (Cognitive Assistant System):** 기억, 주의력, 판단력 등 인간의 인지 능력이 필요한 과업을 보조하고 강화하여 독립적인 생활을 지원하는 시스템. 